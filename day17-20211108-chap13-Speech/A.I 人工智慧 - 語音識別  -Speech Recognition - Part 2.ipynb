{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center' style='color:purple'> Speech Recognition 語音識別 - 課程 01- An Introduction to Speech Recognition - 語音識別 簡介 - Python Tutorial</h1>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "人工智慧-深度學習\n",
    "\n",
    "A.I Tutorials \n",
    "Deep Learning 教程 \n",
    "\n",
    "''' \n",
    "\n",
    "    04 - 課程    - Speech Recognition 語音識別\n",
    "\n",
    "         課程 01 - Speech Recognition \n",
    "                            - An Introduction to Speech Recognition - 語音識別 簡介 \n",
    "         \n",
    "         課程 01 - 語音識別  - 語音識別 簡介\n",
    "         \n",
    "                  \n",
    "                  -  程式範例   - 語音識別   - Speech Recognition                           \n",
    "                                              - Speech to Text \n",
    "\t\t\t\t                              - Text to Speech\n",
    "     \n",
    "'''  教程簡介 '''\n",
    "'''  語音識別 '''\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 語音識別 - Speech Recognition"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 資料準備\n",
    "\n",
    "    >> 你我互動學習園地\n",
    "       >> https://interactiveuandmetutorials.weebly.com/\n",
    "    \n",
    "    >> Python 程式語言 設計\n",
    "       >> https://pythonprogrammingtutorials.weebly.com/\n",
    "\n",
    "    \n",
    ">> 檔案路徑/\n",
    "    ├── 課程 01- An Introduction to Speech Recognition - 語音識別 簡介\n",
    "    ├\n",
    "    ├\n",
    "    ├── audio_files\\\n",
    "              ├──  harvard.wav\n",
    "              ├──  jackhammer.wav\n",
    "              ├──  eng.mp3\n",
    "              ├──  cn.mp3\n",
    "              ├──  cn5.mp3\n",
    "              ├──  hello4.mp3\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OSDisk\n",
      " Volume Serial Number is 382F-FA9C\n",
      "\n",
      " Directory of c:\\python\\20210906-Python-第三階段-13\\day17-20211108-chap13-Speech\\chap13-語音識別_課程\n",
      "\n",
      "11/08/2021  07:38 PM    <DIR>          .\n",
      "11/08/2021  07:38 PM    <DIR>          ..\n",
      "03/25/2020  05:38 PM    <DIR>          audio_files\n",
      "03/25/2020  06:17 PM    <DIR>          data\n",
      "               0 File(s)              0 bytes\n",
      "               4 Dir(s)  347,383,422,976 bytes free\n"
     ]
    }
   ],
   "source": [
    "ddir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\python\\20210906-Python-第三階段-13\\day17-20211108-chap13-Speech\\chap13-語音識別_課程\\audio_files\n"
     ]
    }
   ],
   "source": [
    "cd audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OSDisk\n",
      " Volume Serial Number is 382F-FA9C\n",
      "\n",
      " Directory of c:\\python\\20210906-Python-第三階段-13\\day17-20211108-chap13-Speech\\chap13-語音識別_課程\\audio_files\n",
      "\n",
      "03/25/2020  05:38 PM    <DIR>          .\n",
      "03/25/2020  05:38 PM    <DIR>          ..\n",
      "09/23/2019  02:23 PM            10,762 cn.mp3\n",
      "09/23/2019  02:23 PM            26,540 cn5.mp3\n",
      "09/23/2019  02:22 PM             3,762 cnhello.mp3\n",
      "09/16/2019  11:45 AM            23,712 eng.mp3\n",
      "05/02/2018  09:32 PM         3,249,924 harvard.wav\n",
      "09/23/2019  02:26 PM            16,509 hello4.mp3\n",
      "05/02/2018  09:32 PM           600,204 jackhammer.wav\n",
      "               7 File(s)      3,931,413 bytes\n",
      "               2 Dir(s)  347,384,303,616 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\python\\20210906-Python-第三階段-13\\day17-20211108-chap13-Speech\\chap13-語音識別_課程\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OSDisk\n",
      " Volume Serial Number is 382F-FA9C\n",
      "\n",
      " Directory of c:\\python\\20210906-Python-第三階段-13\\day17-20211108-chap13-Speech\\chap13-語音識別_課程\n",
      "\n",
      "11/08/2021  07:44 PM    <DIR>          .\n",
      "11/08/2021  07:44 PM    <DIR>          ..\n",
      "11/08/2021  07:42 PM    <DIR>          .ipynb_checkpoints\n",
      "03/25/2020  05:38 PM    <DIR>          audio_files\n",
      "03/25/2020  06:17 PM    <DIR>          data\n",
      "               0 File(s)              0 bytes\n",
      "               5 Dir(s)  347,380,510,720 bytes free\n"
     ]
    }
   ],
   "source": [
    "ddir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 語音識別技術：過去，現在 和 未來\n",
    "    >> Speech Recognition Technology: The Past, Present, and Future\n",
    "    \n",
    ">> 聲音是 未來 \n",
    "    >> 從 計算的角度 來看\n",
    "    \n",
    ">> 語音識別 基本上\n",
    "    >> 計算機 軟體 或 硬體設備 是 可以提供 - 人類語音 解碼 能力\n",
    "    \n",
    ">> 可以 用於 執行命令，操作設備 或 寫入\n",
    "    >> 而無需使用 鼠標，鍵盤 或 按任何按鈕\n",
    "        \n",
    ">> 今天，幾乎每項工作任務 \n",
    "    >> 都可以使用 語音命令 和 語音識別進行 自動化，如 安排時間\n",
    "    >> 這些工作任務 \n",
    "    >> 可以由現有 的 個人助理 來執行\n",
    "            \n",
    ">> 例如\n",
    "\n",
    "    >> Siri          - Apple\n",
    "    >> Cortana       - Microsoft\n",
    "    >> Alexia        - Amazon\n",
    "    >> Google        - Assistant     \n",
    "    >> Smart Speaker - Baidu  \n",
    "      \n",
    "      \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 聲音是 未來 - Future\n",
    "    >> 語音識別技術 的歷史\n",
    "    \n",
    ">> 語音識別 技術\n",
    "\n",
    "    >> 人類學 的角度來看\n",
    "    >> 書面語言之前 很久前 就開發了口語\n",
    "    >> 每分鐘可以說 150個 單詞\n",
    "    >> 普通人在 60秒 內 可以 輸入40個 單詞\n",
    "\n",
    ">> 語音識別 - 技術的歷史\n",
    "    >> 可追溯到 18世紀 的重大突破\n",
    "    >> 為 今天所知的 數字助理 \n",
    "    >> 提供了 源頭 及 平台\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/0_MhrkCf5KbJX79YYy.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 語音識別中\n",
    "    >> 最早的進步 主要集中在 \n",
    "    >> 元音 Vowel sounds 的建立\n",
    "\n",
    ">> https://en.wikipedia.org/wiki/Vowel \n",
    "    \n",
    ">> 作為 系統的基礎\n",
    ">> 可以 學習解釋\n",
    "   >> 來自附近 對話者 interlocutors 的 聲音/音素\n",
    "   >> 的語音的 構建塊 - building blocks of speech\n",
    "\n",
    ">> 發明者 受到所處的技術環境 的 阻礙\n",
    "    >> 只有 基本發明一台會 說話的機器\n",
    "     \n",
    ">> 托馬斯愛迪生 Thomas Ediso \n",
    "    >> 19 世紀末 開創了能 聽 寫 的 機器 - 能夠 錄製語音 capable of recording speech \n",
    "       >> doctors and secretaries with a lot of notes to take on a daily basis\n",
    "       \n",
    ">> 直到 20 世紀 50年代，這種發明\n",
    "    >> 導致 真正的語音識別\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 貝爾實驗室 Bell Labs \n",
    "    >> 建立的 Audrey機器 \n",
    "        >> 可以理解 0-9位數，準確率達到 90%\n",
    "    >> 但 這個 準確度 \n",
    "        >> 只有在其 發明者發言 時 才能記錄下來 及達到\n",
    "    >> 當 其他人 與 Audrey機器 交談時\n",
    "        >> 準確度 在 70% 到 80% 之間\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/0_5xnYyyvT7hjQ_EX7.png\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 語音識別 的 挑戰\n",
    "    >> 每個人 都有不同的 聲音 和 口語 可能非常不一致\n",
    "    \n",
    "    >> 與文本/內容的不同，及 語音詞 根據 區域 方言，速度 的不同\n",
    "    >> 甚至 社會階級 和 性別 的不同  都有很大差異\n",
    "    \n",
    ">> 因此\n",
    "    >> 縮放 Scaling\n",
    "    >> 任何語音識別系統 scaling any speech recognition system \n",
    "        >> 一直是一個重大障礙\n",
    "\n",
    ">> 亞歷山大·威貝爾（Alexander Waibel）\n",
    ">> 曾在 卡內基梅隆大學（Carnegie Mellon University）\n",
    "    >> 開發的機器 Harpy上 \n",
    "    >> 可以 理解 超過 1000個 單詞-  1,000 words\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 20世紀 90年代\n",
    "    >> 最成功的系統 基於 模板匹配 Template Matching\n",
    "    >> 將 聲波 sound waves 轉換為一組數 字並 存儲\n",
    "        \n",
    "    >> 當聲音 進入機器時\n",
    "    >> 這意味著\n",
    "        >> 人 必須非常清楚，緩慢地說話\n",
    "        >> 並且在\n",
    "        >> 沒有背景噪音的環境中\n",
    "        >> 才能很好地 識別聲音\n",
    "        \n",
    "        \n",
    ">> IBM Tangora 於20世紀 80年代中期 發佈\n",
    "    >> 以當時世界上最快的打字員 Albert Tangora 的名字命名\n",
    "    >> 可以 適應 發言人的聲音\n",
    "       >> 仍然需要緩慢，清晰的語音和 無背景噪音\n",
    "    >> 使用\n",
    "       >> 馬爾可夫模型 通過 數據聚類\n",
    "       >> 提高了 音頻預測 , 提高了 靈活性   \n",
    "    >> 20 分鐘的 訓練數據（以錄製的語音形式）\n",
    "       >> Tangora 可以識別 \n",
    "       >> 達20,000個 英語單詞 和 一些完整的句子 \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/0_Ry_6Xapk_pUW0vku.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 語音識別 Voice Recognition\n",
    "    >> 是該領域最重要和最重要的 發展之一\n",
    "\n",
    ">> 1997年\n",
    "    >> 世界上第一個 連續語音識別器 - Continuous Speech Recognizer\n",
    "    >> 一個不再需要在每個單詞之間停頓\n",
    "    \n",
    ">> 才在\n",
    "    >> Dragon's NaturallySpeaking 以軟件 的形式發佈\n",
    "    >> 能夠 每分鐘理解 100個 單詞\n",
    "    \n",
    "        \n",
    ">> 機器學習\n",
    "    >> 在語音識別 的突破\n",
    "       \n",
    ">> Google\n",
    "    >> 將最新技術 與 基於雲計算的 強大功能相結合\n",
    "    >> 共享數據\n",
    "    >> 並提高 機器學習演算法的 準確性     \n",
    "\n",
    "\n",
    ">> 還記得嗎 ? \n",
    ">> 2008年 - iPhone\n",
    ">> Google Voice Search 應用程序\n",
    "            \n",
    ">> Siri之後\n",
    "   >> 微軟 推出了Cortana\n",
    "   >> 亞馬遜推出了Alexa    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 語音識別 - 不一定都是 黑盒子 Black Box\n",
    "    >> Speech Recognition Machine Learning isn’t always a Black Box\n",
    "\n",
    ">> 運用 機器學習的網路 來處理 及 訓練 語音\n",
    "    >> Machine Learning / neural network\n",
    "    >> Train it to produce text\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_nJNxFmJaHxyJTtVFkhGTlg.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 最大的問題 是 語音速度 的不同\n",
    "    \n",
    ">> 一個人可能會很快說           -  你好\n",
    "    \n",
    ">> 另一個人可能會 非常緩慢地說   -  你好\n",
    "        \n",
    "    >> heeeelllllllllllllooooo！ \n",
    "    >> 從而生成一個\n",
    "        >> 包含更多數據的 更長聲音 的文件\n",
    "\n",
    ">> 但兩個 聲音文件\n",
    "    >> 都應該 被識別 為完全相同的文本 Text  - 你好\n",
    "    \n",
    ">> 但自動 \n",
    "    >> 將各種長度的音頻文件對齊 \n",
    "    >> 到固定長度 的文本 Text 結果\n",
    "    >> 是相當困難的\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Speech recognition 語音識別\n",
    "    >> 聲音變成 - 位元 Bits\n",
    "    >> Converting Sounds into Bits\n",
    "\n",
    ">> 語音識別的 第一步驟\n",
    ">> 需要將 語音音頻聲波 輸入  電腦 / 計算機 來處理\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_fyZ9oVvMXJ2Y5oMrh_5nkA.jpeg\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 語音識別 的 第一步\n",
    "        \n",
    ">> 需要將 語音音頻聲波 輸入  電腦 / 計算機 來處理\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_zY1qFB9aFfZz66YxxoI2aw.gif\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 從 計算的角度 來看\n",
    "    \n",
    ">> 語音識別\n",
    ">> 基本上\n",
    "    >> 是可以說是 \" 解碼 人類語音  所使用的 計算機/電腦的 軟體 或 硬體 的 設備 \"\n",
    "    \n",
    ">> 通常\n",
    "    >> 用於運行命令，操作設備或寫入，而無需使用鼠標，鍵盤或按任何按鈕\n",
    "    >> 幾乎\n",
    "    >> 都可以 使用 語音命令 和 語音識別 進行執行\n",
    "\n",
    ">> 如 美容沙龍 的 安排時間\n",
    "    \n",
    ">> 這些工作 任務安排\n",
    ">> 可以由現有的個人 語音助理 執行\n",
    "            \n",
    ">> 例如\n",
    "   >> Siri          - Apple\n",
    "   >> Cortana       - Microsoft\n",
    "   >> Alexia        - Amazon\n",
    "   >> Google        - Assistant     \n",
    "   >> Smart Speaker - Baidu \n",
    "                \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_fyZ9oVvMXJ2Y5oMrh_5nkA.jpeg\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 聲音是以 波浪的形式 傳播的\n",
    "    \n",
    ">> 如何將 聲波轉換為 數字？\n",
    "    \n",
    " >> 用這個 \" 你好 \" 聲音片段 Sound Clips\n",
    "         \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7028 sha256=1b553f9075c0e007190dbaaacf49015745672e773cfde8d3678fa32b0b7a9c94\n",
      "  Stored in directory: c:\\users\\lewis_yang\\appdata\\local\\pip\\cache\\wheels\\73\\cd\\cf\\9750b618d54bd81c20e4c34fb24a423a5b095920367cdb3f71\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------- -----------\n",
      "absl-py                 0.13.0\n",
      "aiohttp                 3.7.4.post0\n",
      "argon2-cffi             21.1.0\n",
      "astunparse              1.6.3\n",
      "async-timeout           3.0.1\n",
      "attrs                   21.2.0\n",
      "azure-ai-textanalytics  5.1.0\n",
      "azure-common            1.1.27\n",
      "azure-core              1.19.0\n",
      "backcall                0.2.0\n",
      "bleach                  4.1.0\n",
      "cachetools              4.2.2\n",
      "certifi                 2021.5.30\n",
      "cffi                    1.14.6\n",
      "chardet                 4.0.0\n",
      "charset-normalizer      2.0.4\n",
      "clang                   5.0\n",
      "click                   8.0.3\n",
      "colorama                0.4.4\n",
      "cycler                  0.10.0\n",
      "debugpy                 1.4.1\n",
      "decorator               5.0.9\n",
      "defusedxml              0.7.1\n",
      "entrypoints             0.3\n",
      "et-xmlfile              1.1.0\n",
      "flatbuffers             1.12\n",
      "gast                    0.4.0\n",
      "geoip2                  4.4.0\n",
      "google-auth             1.35.0\n",
      "google-auth-oauthlib    0.4.6\n",
      "google-pasta            0.2.0\n",
      "greenlet                1.1.2\n",
      "grpcio                  1.40.0\n",
      "h5py                    2.10.0\n",
      "idna                    3.2\n",
      "imageai                 2.1.6\n",
      "imageio                 2.9.0\n",
      "ipykernel               6.3.1\n",
      "ipython                 7.27.0\n",
      "ipython-genutils        0.2.0\n",
      "ipywidgets              7.6.4\n",
      "isodate                 0.6.0\n",
      "jedi                    0.18.0\n",
      "jieba                   0.42.1\n",
      "Jinja2                  3.0.1\n",
      "joblib                  1.0.1\n",
      "jsonschema              3.2.0\n",
      "jupyter                 1.0.0\n",
      "jupyter-client          7.0.2\n",
      "jupyter-console         6.4.0\n",
      "jupyter-core            4.7.1\n",
      "jupyterlab-pygments     0.1.2\n",
      "jupyterlab-widgets      1.0.1\n",
      "Keras                   2.4.3\n",
      "Keras-Preprocessing     1.1.2\n",
      "keras-resnet            0.2.0\n",
      "kiwisolver              1.3.2\n",
      "lxml                    4.6.3\n",
      "Markdown                3.3.4\n",
      "MarkupSafe              2.0.1\n",
      "matplotlib              3.3.2\n",
      "matplotlib-inline       0.1.3\n",
      "maxminddb               2.2.0\n",
      "mistune                 0.8.4\n",
      "msrest                  0.6.21\n",
      "multidict               5.2.0\n",
      "nbclient                0.5.4\n",
      "nbconvert               6.1.0\n",
      "nbformat                5.1.3\n",
      "nest-asyncio            1.5.1\n",
      "networkx                2.6.3\n",
      "nltk                    3.6.5\n",
      "notebook                6.4.3\n",
      "numpy                   1.19.3\n",
      "oauthlib                3.1.1\n",
      "OpenCC                  1.1.1\n",
      "opencv-python           4.5.3.56\n",
      "openpyxl                3.0.9\n",
      "opt-einsum              3.3.0\n",
      "packaging               21.0\n",
      "pandas                  1.3.2\n",
      "pandas-datareader       0.10.0\n",
      "pandocfilters           1.4.3\n",
      "parso                   0.8.2\n",
      "pickleshare             0.7.5\n",
      "Pillow                  8.4.0\n",
      "pip                     21.3.1\n",
      "playsound               1.3.0\n",
      "prometheus-client       0.11.0\n",
      "prompt-toolkit          3.0.20\n",
      "protobuf                3.17.3\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pycparser               2.20\n",
      "Pygments                2.10.0\n",
      "pyodbc                  4.0.32\n",
      "pyparsing               2.4.7\n",
      "pyrsistent              0.18.0\n",
      "python-dateutil         2.8.2\n",
      "pytz                    2021.1\n",
      "PyWavelets              1.1.1\n",
      "pywin32                 301\n",
      "pywinpty                1.1.4\n",
      "PyYAML                  5.4.1\n",
      "pyzmq                   22.2.1\n",
      "qtconsole               5.1.1\n",
      "QtPy                    1.11.0\n",
      "regex                   2021.10.8\n",
      "requests                2.26.0\n",
      "requests-oauthlib       1.3.0\n",
      "rsa                     4.7.2\n",
      "scikit-image            0.18.3\n",
      "scikit-learn            0.24.2\n",
      "scipy                   1.4.1\n",
      "Send2Trash              1.8.0\n",
      "setuptools              49.2.1\n",
      "six                     1.15.0\n",
      "SpeechRecognition       3.8.1\n",
      "SQLAlchemy              1.4.26\n",
      "tensorboard             2.6.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.8.0\n",
      "tensorflow-estimator    2.6.0\n",
      "tensorflow-gpu          2.6.0\n",
      "termcolor               1.1.0\n",
      "terminado               0.12.1\n",
      "testpath                0.5.0\n",
      "threadpoolctl           2.2.0\n",
      "tifffile                2021.8.30\n",
      "tornado                 6.1\n",
      "tqdm                    4.62.2\n",
      "traitlets               5.1.0\n",
      "typing-extensions       3.7.4.3\n",
      "urllib3                 1.26.6\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "Werkzeug                2.0.1\n",
      "wget                    3.2\n",
      "wheel                   0.37.0\n",
      "widgetsnbextension      3.5.1\n",
      "wordcloud               1.8.1\n",
      "wrapt                   1.12.1\n",
      "yarl                    1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip list # 1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OSDisk\n",
      " Volume Serial Number is 382F-FA9C\n",
      "\n",
      " Directory of c:\\python\\20210906-Python-第三階段-13\\day17-20211108-chap13-Speech\\chap13-語音識別_課程\\audio_files\n",
      "\n",
      "03/25/2020  05:38 PM    <DIR>          .\n",
      "03/25/2020  05:38 PM    <DIR>          ..\n",
      "09/23/2019  02:23 PM            10,762 cn.mp3\n",
      "09/23/2019  02:23 PM            26,540 cn5.mp3\n",
      "09/23/2019  02:22 PM             3,762 cnhello.mp3\n",
      "09/16/2019  11:45 AM            23,712 eng.mp3\n",
      "05/02/2018  09:32 PM         3,249,924 harvard.wav\n",
      "09/23/2019  02:26 PM            16,509 hello4.mp3\n",
      "05/02/2018  09:32 PM           600,204 jackhammer.wav\n",
      "               7 File(s)      3,931,413 bytes\n",
      "               2 Dir(s)  347,397,849,088 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls \"./audio_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('audio_files\\cnhello.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/speechrecognition.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_6_q1VIVJuavYa-9Uby_L-A.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 聲波是 一維的\n",
    "\n",
    ">> 在每個時間點\n",
    "\n",
    ">> 都有一個 基於 聲波 高度 的單一值\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_dqWhWUIzIyOLIqVReTBaiA.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 聲波 轉換為 數字\n",
    "\n",
    ">> 只需在 等間距點 \n",
    "\n",
    ">> 記錄聲波 的高度\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_dICZCcmEm_EWWx0yA6B3Cw.gif\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 抽樣 - Sampling \n",
    "    >> 每秒 讀取 數千次 原始聲波 - 音頻樣本 數據  \n",
    "    >> 並記錄表示\n",
    "        >> 該時間點 聲波高度 的數字\n",
    "        \n",
    ">> 這基本上\n",
    "    >> 都是一個未壓縮 的.wav 音頻文件\n",
    "        \n",
    ">> CD 質量 音頻採樣  為 44.1khz（每秒讀數為 44,100）的採樣率- sampling rate\n",
    "        \n",
    ">> 語音識別 音頻採樣 為 16 khz （每秒16,000個 樣本） 的採樣率 - sampling rate\n",
    "   >> 足以覆蓋人類語音 的 頻率範圍\n",
    "   >> 每秒 16,000 次 採樣 \n",
    "  \n",
    ">> 下圖表示\n",
    "   >> “ Hello” 聲波 sound wave\n",
    "   >> 前 - 100 個樣本 100 samples\n",
    "    \n",
    ">> 每個數字表示\n",
    "   >> 聲波的 幅度為 1/16000秒 的 間隔\n",
    "   >> Sound Wave at 1/16000th of a second intervals\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_BG4iFbx7qhb5v_JTr958PQ.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_KkWfr3a6HtRSZ8-4LUw0kg.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 奈奎斯特 定理 -  Nyquist Theorem\n",
    "    \n",
    ">> 使用 數學式 \n",
    "    >> 來 重建 音頻樣本 數據  中的  原始聲波 \n",
    "\n",
    ">> 採樣 的速度\n",
    "    >> 至少\n",
    "        >> 是 想要記錄 最高頻率 的兩倍\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Speech - Text \n",
    "    \n",
    ">> 語音 -  文本 / 文字\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/speech-recognition-python.png\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/crm-voice_recognition_mobile.png\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 預處理 -  採樣 音頻數據\n",
    "    >> Pre-processing our Sampled Sound Data\n",
    "    \n",
    ">> 有一個 數字數組\n",
    "    >> 每個數字 代表聲波 的振幅，以 1/16,000秒為 間隔\n",
    "    \n",
    ">>音頻數據 進行一些 預處理\n",
    "    >> 以便以後 這些音頻數據 - 輸入神經網絡\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/speech-recognition-python-1.png\" width=\"75%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 採樣 音頻 為 20毫秒長 的音頻塊\n",
    "    \n",
    ">> 前 20毫秒 音頻塊 - 320 個 樣本\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1__qUExEvllTKFhsrITxsa-A.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 繪製 20毫秒 的折線圖 - Simple Line Graph\n",
    "    >> 20 millisecond period of time\n",
    "    \n",
    ">> 20毫秒  的 原始聲波\n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_ZMxcyjNFqIOVzJRM9BCMWw.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    ">> 神經網絡 更容易處理 這些數據\n",
    "    >> Neural Network Process\n",
    "    \n",
    ">> 將複雜的 聲波 分解成 它的 組成部分\n",
    "    >> complex sound wave into it’s component parts\n",
    "    \n",
    ">> 分解 \n",
    "    >> 低音調 部分 Low-Pitched Parts ，及 下一個 低音調 部分，等等\n",
    "    >> 然後通過 計算每個 頻段（從低到高）的音頻能量\n",
    "    \n",
    ">> 為此 音頻片段  audio snippet 轉換成 數值\n",
    "\n",
    "\n",
    ">> 傅立葉變換 的 數學運算\n",
    "    >> 將椱雜的聲波 分解 成 簡單的聲波\n",
    "    >>一旦獲得了那些 單獨的聲波，\n",
    "    >> 就會計算每個聲波中\n",
    "    >> 包含多少音頻能量\n",
    "\n",
    ">> https://en.wikipedia.org/wiki/Fourier_transform\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_2Vg8z3--moE-E7KybJlUPg.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 繪製 音頻塊 - 頻譜圖 - Spectrogram \n",
    "\n",
    ">> 圖表\n",
    "    >> 20毫秒 聲音片段 - 具有大量的 低頻能量\n",
    "    >> 較高頻率下\n",
    "    >> 沒有太多能量\n",
    "       >> 典型的 “ 男性 ” 聲音\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_A4CxgdyqYd_nrF3e-7ETWA.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 頻譜圖 - Spectrogram\n",
    ">> 每 20毫秒 的音頻塊 上 \n",
    "    >> 重複 這個過程\n",
    "    >> 得到一個 頻譜圖 \n",
    "    \n",
    "\n",
    ">> 下圖中表示 每個列 從 左 到 右 是一個 20ms 的音頻塊\n",
    "    \n",
    ">> 音頻數據中 - 看到 音符 和其他 音高模式\n",
    "    >>  musical notes and other pitch patterns in audio data\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_bhd7B-s-Qnds3HGV6LOo8A.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 短的聲音 -識別字符\n",
    ">> Recognizing Characters from Short Sounds\n",
    "\n",
    ">> 音頻格式 易於處理\n",
    "    >> 提供給深度神經網絡 - Deep Neural Network\n",
    "    \n",
    ">> 神經網絡- 輸入是 20毫秒 的 音頻塊\n",
    "    >> 對於 每個小音頻 切片\n",
    "    \n",
    "> > 嘗試找出 與 當前所說聲音 - 相對應 的字母\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/speech-recognition-python-1.png\" width=\"75%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_z1Nf0ES1YVUfdZZGW0PSdQ.png\" width=\"75%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 遞歸 / 循環 神經網絡 \n",
    ">> Recurrent Neural Network \n",
    "    \n",
    ">> 預測的 每個字母都 會影響 預測 下一個字母 的可能性\n",
    "    \n",
    ">> 通過神經網絡（一次一個塊）運行 整個音頻 剪輯之後\n",
    ">> 最終會\n",
    "    >> 得到 每個 音頻區塊 \n",
    "    >> 最有可能\n",
    "    >> 說出的字母 的映射 Mapping\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_d1ktMdOnFOJRKKyjFP6sqQ.png\" width=\"75%\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 神經網絡 預測\n",
    "    \n",
    "    >> 一個可能的文字 是 -\n",
    "        >> HHHEE_LL_LLLOOO\n",
    "    \n",
    "    >> 也有可能 認為\n",
    "        >> HHHUU_LL_LLLOOO\n",
    "      >> 或\n",
    "        >> 有可能 - AAAUU_LL_LLLOOO\n",
    "    \n",
    "    >> 需要 有一些步驟來 清理/ 處理 這個輸出\n",
    "        >> 首先\n",
    "            \n",
    "            \n",
    "    >> 替換 任何重複字符 的單個字符\n",
    "\n",
    "        >> HHHEE_LL_LLLOOO 變為 >> HE_L_LO\n",
    "        >> HHHUU_LL_LLLOOO 變為 >> HU_L_LO\n",
    "        >> AAAUU_LL_LLLOOO 變為  >> AU_L_LO\n",
    "\n",
    "    >> 然後刪除 任何空白字符\n",
    "    \n",
    "        >> HE_L_LO 變為  >> HELLO\n",
    "        >> HU_L_LO 變成  >> HULLO\n",
    "        >> AU_L_LO 變為  >> AULLO\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/1_bhd7B-s-Qnds3HGV6LOo8A.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 當前 語音識別 領域 中\n",
    "    >> Speech Recognition Landscape\n",
    "    \n",
    "    \n",
    ">> 智能 / 智慧型 手機\n",
    "        \n",
    "   >> 數字助理 最初是 Siri 和 Cortana\n",
    "            \n",
    ">> 過去幾年中 已經運用到更多的 產品\n",
    "        \n",
    "   >> 目前\n",
    "   >> 重點主要\n",
    "   >> 放在 語音激活的 家庭揚聲器上 voice-activated home speakers\n",
    "           \n",
    "   >> 這些 揚聲器/ 喇叭- Speakers是 智能設備激增的 使用者/門戶之一\n",
    "                \n",
    "   >> 可以在廣泛的 使用在\n",
    "   >> 物聯網 IoT Internet of Thing -\n",
    "       >> Google Home 或 Amazon Echo\n",
    "       >> 控制 大量 支持 互聯網的設備  Internet-Enabled Devices \n",
    "                \n",
    "   >> 到了 2020 年\n",
    "      >> 還有更多的設備 會加入\n",
    "      >> 包括\n",
    "      >> 智能冰箱 Smart Refridges\n",
    "      >> 耳機 headphones\n",
    "      >> 鏡子 Mirrors \n",
    "      >> 煙霧報警器 Smoke Alarms\n",
    "      >> 以及 Integrations \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> GOOGLE Home\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/u_10161441.jpg\" width=\"25%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Apple - Siri Speaker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/6a0120a5580826970c01b8d2e6f2c9970c-800wi.jpg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 亞馬遜 - Amazon Echo - Alexa\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/img-1546900059-78620@600.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/0_Ub31UBdmA3Xx9eri.jpg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Baidu Smart Speaker - 百度 智能音箱\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/Moto-AI-Speakers-Amazon-Echo13.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 程式範例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 導入相關的 函式庫"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 導入 相關 函式庫 \n",
    "   \n",
    ">> Import Relative Library\n",
    "   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\python38\\lib\\site-packages (3.8.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 安裝 SpeechRecognition 語音識別 - 函式庫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/Uberi/speech_recognition#readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------- -----------\n",
      "absl-py                 0.13.0\n",
      "aiohttp                 3.7.4.post0\n",
      "argon2-cffi             21.1.0\n",
      "astunparse              1.6.3\n",
      "async-timeout           3.0.1\n",
      "attrs                   21.2.0\n",
      "azure-ai-textanalytics  5.1.0\n",
      "azure-common            1.1.27\n",
      "azure-core              1.19.0\n",
      "backcall                0.2.0\n",
      "bleach                  4.1.0\n",
      "cachetools              4.2.2\n",
      "certifi                 2021.5.30\n",
      "cffi                    1.14.6\n",
      "chardet                 4.0.0\n",
      "charset-normalizer      2.0.4\n",
      "clang                   5.0\n",
      "click                   8.0.3\n",
      "colorama                0.4.4\n",
      "cycler                  0.10.0\n",
      "debugpy                 1.4.1\n",
      "decorator               5.0.9\n",
      "defusedxml              0.7.1\n",
      "entrypoints             0.3\n",
      "et-xmlfile              1.1.0\n",
      "flatbuffers             1.12\n",
      "gast                    0.4.0\n",
      "geoip2                  4.4.0\n",
      "google-auth             1.35.0\n",
      "google-auth-oauthlib    0.4.6\n",
      "google-pasta            0.2.0\n",
      "greenlet                1.1.2\n",
      "grpcio                  1.40.0\n",
      "h5py                    2.10.0\n",
      "idna                    3.2\n",
      "imageai                 2.1.6\n",
      "imageio                 2.9.0\n",
      "ipykernel               6.3.1\n",
      "ipython                 7.27.0\n",
      "ipython-genutils        0.2.0\n",
      "ipywidgets              7.6.4\n",
      "isodate                 0.6.0\n",
      "jedi                    0.18.0\n",
      "jieba                   0.42.1\n",
      "Jinja2                  3.0.1\n",
      "joblib                  1.0.1\n",
      "jsonschema              3.2.0\n",
      "jupyter                 1.0.0\n",
      "jupyter-client          7.0.2\n",
      "jupyter-console         6.4.0\n",
      "jupyter-core            4.7.1\n",
      "jupyterlab-pygments     0.1.2\n",
      "jupyterlab-widgets      1.0.1\n",
      "Keras                   2.4.3\n",
      "Keras-Preprocessing     1.1.2\n",
      "keras-resnet            0.2.0\n",
      "kiwisolver              1.3.2\n",
      "lxml                    4.6.3\n",
      "Markdown                3.3.4\n",
      "MarkupSafe              2.0.1\n",
      "matplotlib              3.3.2\n",
      "matplotlib-inline       0.1.3\n",
      "maxminddb               2.2.0\n",
      "mistune                 0.8.4\n",
      "msrest                  0.6.21\n",
      "multidict               5.2.0\n",
      "nbclient                0.5.4\n",
      "nbconvert               6.1.0\n",
      "nbformat                5.1.3\n",
      "nest-asyncio            1.5.1\n",
      "networkx                2.6.3\n",
      "nltk                    3.6.5\n",
      "notebook                6.4.3\n",
      "numpy                   1.19.3\n",
      "oauthlib                3.1.1\n",
      "OpenCC                  1.1.1\n",
      "opencv-python           4.5.3.56\n",
      "openpyxl                3.0.9\n",
      "opt-einsum              3.3.0\n",
      "packaging               21.0\n",
      "pandas                  1.3.2\n",
      "pandas-datareader       0.10.0\n",
      "pandocfilters           1.4.3\n",
      "parso                   0.8.2\n",
      "pickleshare             0.7.5\n",
      "Pillow                  8.4.0\n",
      "pip                     21.3.1\n",
      "playsound               1.3.0\n",
      "prometheus-client       0.11.0\n",
      "prompt-toolkit          3.0.20\n",
      "protobuf                3.17.3\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pycparser               2.20\n",
      "Pygments                2.10.0\n",
      "pyodbc                  4.0.32\n",
      "pyparsing               2.4.7\n",
      "pyrsistent              0.18.0\n",
      "python-dateutil         2.8.2\n",
      "pytz                    2021.1\n",
      "PyWavelets              1.1.1\n",
      "pywin32                 301\n",
      "pywinpty                1.1.4\n",
      "PyYAML                  5.4.1\n",
      "pyzmq                   22.2.1\n",
      "qtconsole               5.1.1\n",
      "QtPy                    1.11.0\n",
      "regex                   2021.10.8\n",
      "requests                2.26.0\n",
      "requests-oauthlib       1.3.0\n",
      "rsa                     4.7.2\n",
      "scikit-image            0.18.3\n",
      "scikit-learn            0.24.2\n",
      "scipy                   1.4.1\n",
      "Send2Trash              1.8.0\n",
      "setuptools              49.2.1\n",
      "six                     1.15.0\n",
      "SpeechRecognition       3.8.1\n",
      "SQLAlchemy              1.4.26\n",
      "tensorboard             2.6.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.8.0\n",
      "tensorflow-estimator    2.6.0\n",
      "tensorflow-gpu          2.6.0\n",
      "termcolor               1.1.0\n",
      "terminado               0.12.1\n",
      "testpath                0.5.0\n",
      "threadpoolctl           2.2.0\n",
      "tifffile                2021.8.30\n",
      "tornado                 6.1\n",
      "tqdm                    4.62.2\n",
      "traitlets               5.1.0\n",
      "typing-extensions       3.7.4.3\n",
      "urllib3                 1.26.6\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "Werkzeug                2.0.1\n",
      "wget                    3.2\n",
      "wheel                   0.37.0\n",
      "widgetsnbextension      3.5.1\n",
      "wordcloud               1.8.1\n",
      "wrapt                   1.12.1\n",
      "yarl                    1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> SpeechRecognition 語音識別 - 函式庫 Library\n",
    "    \n",
    "    >> https://pypi.org/project/SpeechRecognition/\n",
    "\n",
    "    >> pip install SpeechRecognition\n",
    "\n",
    ">> https://github.com/Uberi/speech_recognition#readme\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.1\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "print(sr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "> 音頻文件中 獲取數據\n",
    ">> record()\n",
    "    \n",
    "\n",
    "\n",
    "recognize_bing()        : Microsoft Bing Speech\n",
    "recognize_google()      : Google Web Speech API\n",
    "recognize_google_cloud(): Google Cloud Speech - requires installation of the google-cloud-speech package\n",
    "recognize_houndify()    : Houndify by SoundHound\n",
    "recognize_ibm()         : IBM Speech to Text\n",
    "recognize_sphinx()      : CMU Sphinx - requires installing PocketSphinx\n",
    "recognize_wit()         : Wit.ai\n",
    "\n",
    ">> Recognizer API \n",
    "    \n",
    "    >> 主要用於 - 識別語音\n",
    "    >> 每個 API 都有 多個 功能 及 參數 設置 來 識別音頻 源 的工具\n",
    "    \n",
    ">> recognition_sphinx()\n",
    "        >> 可以 與 CMU Sphinx 引擎       - Offline 使用\n",
    "        \n",
    "        >> 其他 六個需要 連接 到 Internet - Online 使用\n",
    "        \n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 音頻 - 支持 的 文件類型\n",
    "    \n",
    ">> SpeechRecognition \n",
    "\n",
    ">> 目前支持以下 文件類型\n",
    "\n",
    "   >> WAV       : 必須是 PCM / LPCM 格式\n",
    "   >> AIFF\n",
    "   >> AIFF-C\n",
    "   >> FLAC      : 必須是 原始的 FLAC 格式\n",
    "   >> OGG-FLAC  : 格式 不可用\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio_files\\harvard.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.recognize_bing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RequestError",
     "evalue": "credential request failed: Access Denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_bing\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m   1021\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m                 \u001b[0mcredential_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredential_request\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# credential response can take longer, use longer timeout instead of default one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
      "\u001b[1;32mc:\\python38\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 401: Access Denied",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRequestError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LEWIS_~1\\AppData\\Local\\Temp/ipykernel_21124/1586507995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mharvard\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m    \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_bing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b212343ddb5348938e2c5cdc4269589b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_bing\u001b[1;34m(self, audio_data, key, language, show_all)\u001b[0m\n\u001b[0;32m   1022\u001b[0m                 \u001b[0mcredential_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredential_request\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# credential response can take longer, use longer timeout instead of default one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRequestError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"credential request failed: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRequestError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"credential connection failed: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRequestError\u001b[0m: credential request failed: Access Denied"
     ]
    }
   ],
   "source": [
    "harvard = sr.AudioFile('audio_files\\harvard.wav')\n",
    "with harvard as source:\n",
    "   audio = r.record(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> record()函數\n",
    "\n",
    ">> 將整個音頻 文件數據 讀入 Audio_Data \n",
    "\n",
    ">> 可以 檢查 音頻類型\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.AudioData"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvard = sr.AudioFile('audio_files\\cnhello.wav')\n",
    "with harvard as source:\n",
    "   audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.recognize_google?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio, language='zh-TW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Microsoft Bing Speech API \n",
    "# https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/get-started-speech-to-text?tabs=windowsinstall&pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-speech"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading azure_cognitiveservices_speech-1.19.0-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "Installing collected packages: azure-cognitiveservices-speech\n",
      "Successfully installed azure-cognitiveservices-speech-1.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak into your microphone.\n",
      "The holy.\n"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "def from_mic():\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=\"b212343ddb5348938e2c5cdc4269589b\", \n",
    "                                       region=\"southeastasia\")\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n",
    "    \n",
    "    print(\"Speak into your microphone.\")\n",
    "    result = speech_recognizer.recognize_once_async().get()\n",
    "    print(result.text)\n",
    "\n",
    "from_mic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 捕獲音頻 及 處理音頻時間 的 剪輯 及 偏移\n",
    "\n",
    "    >>> with harvard as source:\n",
    "    ... audio = r.record(source, duration=4)\n",
    "    ...\n",
    "\n",
    ">>> sr.recognize_google(audio)\n",
    "    'the stale smell of old beer lingers'\n",
    "\n",
    ">> 前四秒 音頻 將保存在 audio1 中，後四秒鐘 音頻 將保存在 audio2 中\n",
    "\n",
    "    >>> with harvard as source:\n",
    "    ... audio1 = sr.record(source, duration=4)\n",
    "    ... audio2 = sr.record(source, duration=4)\n",
    "    ...\n",
    "\n",
    ">>> sr.recognize_google(audio1)\n",
    "    'the stale smell of old beer lingers'\n",
    "\n",
    ">>> sr.recognize_google(audio2)\n",
    "    'it takes heat to bring out the odor a cold dip'\n",
    "\n",
    ">> 偏移設置為 4 秒，並記錄 持續時間 3秒\n",
    "\n",
    ">>> with harvard as source:\n",
    "    ... audio = sr.record(source, offset=4, duration=3)\n",
    "    ...\n",
    "\n",
    ">>> recognizer.recognize_google(audio)\n",
    "    'it takes heat to bring out the odor'\n",
    "\n",
    ">> 事先知道文件的 語音結構時\n",
    "    >> 偏移 和 持續時間 \n",
    "        >> 關鍵字參數 設置 對於 分割音頻文件 非常有用\n",
    "    \n",
    "    >> 但不准確的使用 會導致 轉錄不良\n",
    "\n",
    ">>> with harvard as source:\n",
    "    ... audio = r.record(source, offset=4.7, duration=2.8)\n",
    "    ...\n",
    "\n",
    ">>> recognizer.recognize_google(audio)\n",
    "\n",
    "\n",
    ">> 上面的 程式範例\n",
    "    >> 記錄音頻 案例 \n",
    "    >> 從 4.7秒 開始\n",
    "    >> 因此 短語 “it t” 中 的短語 “ 前面的 內容 ” 並沒有記錄\n",
    "        >> 並且API只獲得輸入“ akes hea t” \n",
    "    \n",
    "    >> 匹配結果“ Mesquite ” \n",
    "    \n",
    "    >> 類似地，API 僅在 錄音結束時\n",
    "        >> 捕獲的 音頻 並不匹配\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio_files\\jackhammer.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvard = sr.AudioFile('audio_files\\jackhammer.wav')\n",
    "with harvard as source:\n",
    "   audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.AudioData"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the snail smell of old beer drinkers'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://www.code-learner.com/python-speech-recognition-introduction-and-practice/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 噪聲 對 語音識別的 影響\n",
    "    \n",
    ">> 日常生活/現實世界中 存在的 噪聲\n",
    "    >> 都有 一定程度的噪音\n",
    "\n",
    ">> 未經處理 的噪音 \n",
    "    >> 會破壞 及 減少 在語音識別應用 的準確性\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\python38\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\lewis_yang\\\\AppData\\\\Local\\\\Temp\\\\pip-install-b4dsuihl\\\\pyaudio_3646a739f5b746f4805d89113118c1e1\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\lewis_yang\\\\AppData\\\\Local\\\\Temp\\\\pip-install-b4dsuihl\\\\pyaudio_3646a739f5b746f4805d89113118c1e1\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\lewis_yang\\AppData\\Local\\Temp\\pip-wheel-rifmfwe6'\n",
      "       cwd: C:\\Users\\lewis_yang\\AppData\\Local\\Temp\\pip-install-b4dsuihl\\pyaudio_3646a739f5b746f4805d89113118c1e1\\\n",
      "  Complete output (9 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  copying src\\pyaudio.py -> build\\lib.win-amd64-3.8\n",
      "  running build_ext\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached PyAudio-0.2.11.tar.gz (37 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pyaudio\n",
      "  Building wheel for pyaudio (setup.py): started\n",
      "  Building wheel for pyaudio (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyaudio\n",
      "Failed to build pyaudio\n",
      "Installing collected packages: pyaudio\n",
      "    Running setup.py install for pyaudio: started\n",
      "    Running setup.py install for pyaudio: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  building '_portaudio' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyaudio\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'c:\\python38\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\lewis_yang\\\\AppData\\\\Local\\\\Temp\\\\pip-install-b4dsuihl\\\\pyaudio_3646a739f5b746f4805d89113118c1e1\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\lewis_yang\\\\AppData\\\\Local\\\\Temp\\\\pip-install-b4dsuihl\\\\pyaudio_3646a739f5b746f4805d89113118c1e1\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\lewis_yang\\AppData\\Local\\Temp\\pip-record-7batgvn3\\install-record.txt' --single-version-externally-managed --compile --install-headers 'c:\\python38\\Include\\pyaudio'\n",
      "         cwd: C:\\Users\\lewis_yang\\AppData\\Local\\Temp\\pip-install-b4dsuihl\\pyaudio_3646a739f5b746f4805d89113118c1e1\\\n",
      "    Complete output (9 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.8\n",
      "    copying src\\pyaudio.py -> build\\lib.win-amd64-3.8\n",
      "    running build_ext\n",
      "    building '_portaudio' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'c:\\python38\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\lewis_yang\\\\AppData\\\\Local\\\\Temp\\\\pip-install-b4dsuihl\\\\pyaudio_3646a739f5b746f4805d89113118c1e1\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\lewis_yang\\\\AppData\\\\Local\\\\Temp\\\\pip-install-b4dsuihl\\\\pyaudio_3646a739f5b746f4805d89113118c1e1\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\lewis_yang\\AppData\\Local\\Temp\\pip-record-7batgvn3\\install-record.txt' --single-version-externally-managed --compile --install-headers 'c:\\python38\\Include\\pyaudio' Check the logs for full command output.\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\python38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pyaudio\n",
    "# https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    ">> 麥克風 做為 輸入裝置 需要考慮 噪聲 的影響\n",
    "\n",
    ">> The Microphone input\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip install pyaudio"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 使用 麥克風  做為輸入裝置\n",
    "    \n",
    ">> SpeechRecognizer 使用 麥克風\n",
    "\n",
    ">> 需要 安裝 PyAudio 函式庫\n",
    "   \n",
    "    >>  pip install pyaudio\n",
    " \n",
    "- import speech_recognition as sr\n",
    "- r = sr.Recognizer() \n",
    "- mic = sr.Microphone()\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft 音效對應表 - Input',\n",
       " 'Microphone (sabinetek usb audio',\n",
       " 'Microphone (Realtek High Defini',\n",
       " 'Microsoft 音效對應表 - Output',\n",
       " 'Speakers (Realtek High Definiti',\n",
       " '喇叭 (sabinetek usb audio)',\n",
       " 'Microphone (Realtek HD Audio Mic input)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " 'Stereo Mix (Realtek HD Audio Stereo input)',\n",
       " 'Speakers (sabinetek usb audio)',\n",
       " 'Microphone (sabinetek usb audio)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mic as source:\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello everybody good day'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 如何 處理 環境 噪聲 Noise \n",
    "\n",
    "    - adjust_for_ambient_noise() - 處理 環境的噪音\n",
    "    \n",
    ">> Recognizer 的 API - adjust_for_ambient_noise()函數\n",
    "    >> 對 噪聲音頻文件 有處理的能力\n",
    "    \n",
    ">> 由於麥克風輸入聲音 的 可預測性 - 低於 音頻文件\n",
    "    \n",
    "    - adjust_for_ambient_noise() \n",
    "    - 默認調整為 (1秒 長) 的音頻源\n",
    "        \n",
    ">>  如何 認為 時間太長，也可以 調整參數 - Duration = 1.5 秒\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mic as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello good day'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " '''\n",
    "\n",
    ">> 難以 識別的 語音過程\n",
    ">> 經由麥克風中的輸入, 通常會有一些 難以理解 的噪音\n",
    "    \n",
    ">> 語音識別  的 函式庫 API , 有時 無法完成  與 文本 匹配 的音頻\n",
    "\n",
    ">> 將導致 UnknownValueError\n",
    "   \n",
    ">> 因此\n",
    "   >> try 和 except 程式代碼 \n",
    "   >> 經常用於解決此問題\n",
    "   >> 語音識別  的 函式庫 API 將 所有可能的任何聲音 轉換 為 文本\n",
    "        \n",
    ">> 例如\n",
    "   >> 可能被識別為 “ 如何 ” 的 短咕嚕聲\n",
    "   >> 可能被轉換為 文本 並 導致異常的 咳嗽，掌聲 或 舌頭 咔嗒聲\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 文本 到 語音\n",
    "\n",
    ">> Text To Speech \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stale smell of old beer lingers it takes heat to bring out the odor a cold dip restores health and zest a salt pickle taste fine with ham tacos al Pastore are my favorite a zestful food is be hot cross bun'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile('audio_files\\harvard.wav') as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "r.recognize_google(audio, language='eg') # language='zh-tw' -> 繁體中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()\n",
    "engine.say(\"I will speak this text\")\n",
    "engine.say(\"台灣是個美麗的寶島\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtts.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = \" 你好 \"\n",
    "obj = gTTS(text = tw, slow = False, lang = 'zh-tw') ## en \n",
    "obj.save('audio_files\\cnhello.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = \" 台灣是個美麗的寶島\"\n",
    "obj = gTTS(text = tw, slow = False, lang = 'zh-tw') ## en \n",
    "obj.save('audio_files\\cn.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = \" 強！郭婞淳挺舉140公斤 破世界紀錄奪金 \"\n",
    "obj = gTTS(text = tw, slow = False, lang = 'zh-tw') ## en \n",
    "obj.save('audio_files\\cn5.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_obj = sa.WaveObject.from_wave_file(\"audio_files\\harvard.wav\") # harvard.wav\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_obj = sa.WaveObject.from_wave_file(\"audio_files\\jackhammer.wav\") # jackhammer.wav\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('audio_files\\cn5.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('audio_files\\cn.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('audio_files\\cnhello.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition\n",
    "r = speech_recognition.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with speech_recognition.Microphone() as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大家好'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio, language='zh-TW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "tts = gTTS(text='大家好 !  祝大家有個美好的一天', lang='zh-tw')\n",
    "tts.save(\"audio_files\\hello4.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pygame import mixer\n",
    "mixer.init()\n",
    "mixer.music.load('audio_files\\hello4.mp3')\n",
    "mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "def speak(sentence):\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as fp:\n",
    "        tts = gTTS(text=sentence, lang='zh-tw')\n",
    "        tts.save(\"{}.mp3\".format(fp.name))\n",
    "        mixer.music.load('{}.mp3'.format(fp.name))\n",
    "        mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak('大家好!祝大家有個美好的一天')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip install pygame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 安裝 pygame 函式庫\n",
    "\n",
    ">> pip install pygame \n",
    "\n",
    ">> https://www.pygame.org/\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import speech_recognition\n",
    "\n",
    "def listenTo():\n",
    "    r = speech_recognition.Recognizer()\n",
    "\n",
    "    with speech_recognition.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    return r.recognize_google(audio, language='zh-TW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from gtts import gTTS\n",
    "from pygame import mixer\n",
    "mixer.init()\n",
    "\n",
    "def speak(sentence):\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as fp:\n",
    "        tts = gTTS(text=sentence, lang='zh-tw')\n",
    "        tts.save(\"{}.mp3\".format(fp.name))\n",
    "        mixer.music.load('{}.mp3'.format(fp.name))\n",
    "        mixer.music.play()\n",
    "        \n",
    "speak('大家好!祝大家有個美好的一天')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak(listenTo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer = {\n",
    "  '你好嗎'    : '我很好',\n",
    "  '你很帥'    : '謝謝啦 !',\n",
    "  '再見了'    : '下次見了! 再聊 ! 拜拜'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak(Answer.get(listenTo(), '對不起，聽不清楚 ! 請再說一變，謝謝啦 ! 再回答你'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讓 我們 繼續 看下去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

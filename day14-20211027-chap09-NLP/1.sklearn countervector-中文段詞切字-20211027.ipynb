{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement jieba==0 (from versions: 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.26.1, 0.27, 0.28, 0.28.1, 0.28.2, 0.28.3, 0.28.4, 0.29, 0.29.1, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.36.2, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.42.1)\n",
      "ERROR: No matching distribution found for jieba==0\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.42.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dir(jieba))\n",
    "jieba.cut_for_search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這是', '第一篇', '文章', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "list(jieba.cut(sentence = '這是第一篇文章.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode: 小, 明, 碩, 士, 畢, 業, 于, 台, 灣, 大, 學, 電, 機, 所, ，, 後, 在, 日本, 京都, 大, 學, 深造\n",
      "Default Mode: 小明, 碩士, 畢業于, 台灣, 大學, 電機, 所, ，, 後, 在, 日本, 京都, 大學, 深造\n",
      "小明, 碩士, 畢業于, 台灣, 大學, 電機, 所, ，, 後, 在, 日本, 京都, 大學, 深造\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"小明碩士畢業于台灣大學電機所，後在日本京都大學深造\", cut_all=True)\n",
    "print(\"Full Mode: \" + \", \".join(seg_list))  # 全模式\n",
    "seg_list = jieba.cut(\"小明碩士畢業于台灣大學電機所，後在日本京都大學深造\", cut_all=False)\n",
    "print(\"Default Mode: \" + \", \".join(seg_list))  # 精確模式\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明碩士畢業于台灣大學電機所，後在日本京都大學深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['並且', '嗎', '文章', '是', '第一篇', '第三篇', '第二篇', '這', '這是'], dtype='<U3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "corpus = [\n",
    "    '這是第一篇文章',\n",
    "    '這文章是第二篇',\n",
    "    '並且這是第三篇',\n",
    "    '這是第一篇文章嗎',\n",
    "]\n",
    "words = []\n",
    "for c in corpus :\n",
    "    words.extend( list(jieba.cut(sentence = c )) )\n",
    "np.unique( words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這是', '第一篇', '文章', ' ', 'Microsoft', ' ', 'windows', ' ', '10']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手動轉換成 \n",
    "# Sentence to vector \n",
    "#  [[0 1 1 1 0 0 1 0 1]\n",
    "#  [0 2 0 1 0 1 1 0 1]\n",
    "#  [1 0 0 1 1 0 1 1 1]\n",
    "#  [0 1 1 1 0 0 1 0 1]]\n",
    "\n",
    "list(jieba.cut(sentence = '這是第一篇文章 Microsoft windows 10' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 思考\n",
    "# ['這是', '第一篇', '文章'] \n",
    "# ['並且', '嗎', '文章', '是', '第一篇', '第三篇', '第二篇', '這', '這是']\n",
    "# [0    ,    0,      1,    0,        1,       0,        0,   0,      1]\n",
    "zh_all = np.unique( words )\n",
    "zh_cv = np.zeros([4,9]).astype('int')\n",
    "###############################################\n",
    "#字頻分析表\n",
    "##############################################\n",
    "# 從文章中取出 每一 kk=序號， vv=每一條文章內容\n",
    "for kk,vv in enumerate(corpus):\n",
    "    # 針對 vv 每一個文章內容去切字\n",
    "    for v in list(jieba.cut(sentence = vv )):\n",
    "        # 針對 每一個單字 進行 轉換 1 \n",
    "        pos = np.where(zh_all == v)\n",
    "        zh_cv[kk, pos] = 1\n",
    "zh_cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5)\n",
      "(1, 6)\n",
      "(2, 7)\n"
     ]
    }
   ],
   "source": [
    "# enumerate\n",
    "for i in enumerate(range(5, 8)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.28867513, 0.33333333, 0.8660254 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(zh_cv[0].reshape(1,-1), zh_cv).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = [\n",
    "#     '這是第一篇文章',\n",
    "#     '這文章是第二篇',\n",
    "#     '並且這是第三篇',\n",
    "#     '這是第一篇文章嗎',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['這是 第一篇 文章', '這 文章 是 第二篇', '並且 這是 第三篇', '這是 第一篇 文章 嗎']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "corpus = [\n",
    "    '這是第一篇文章',\n",
    "    '這文章是第二篇',\n",
    "    '並且這是第三篇',\n",
    "    '這是第一篇文章嗎',\n",
    "]\n",
    "words = []\n",
    "for c in corpus :\n",
    "    words.append( ' '.join(list(jieba.cut(sentence = c ))) )\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.53256952, 0.        , 0.65782931,\n",
       "        0.        , 0.        , 0.        , 0.53256952],\n",
       "       [0.        , 0.        , 0.34578314, 0.5417361 , 0.        ,\n",
       "        0.        , 0.5417361 , 0.5417361 , 0.        ],\n",
       "       [0.64450299, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.64450299, 0.        , 0.        , 0.41137791],\n",
       "       [0.        , 0.64065543, 0.40892206, 0.        , 0.5051001 ,\n",
       "        0.        , 0.        , 0.        , 0.40892206]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(zh_cv)\n",
    "tfidf.toarray().shape # 四篇文章 所有的單字 \n",
    "tfidf.toarray() # 該部分類似 CountVectorizer() 顯示單字出現的頻率，加上權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76782851, 0.14139835, 0.1682215 , 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 3\n",
    "similarity_subject = np.array(cosine_similarity(tfidf[base], tfidf)).ravel()\n",
    "similarity_subject"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# songname = \"./genres/blues/blues.00000.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# cmap = plt.get_cmap('inferno')\n",
    "# plt.figure(figsize=(10,10))\n",
    "\n",
    "# y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "# plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "# plt.axis('off');\n",
    "# plt.savefig('./blues.00000.wav.png')\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 第一 將每一種歌曲型態轉換成Spectrogram\n",
    "# # 第二 參考CNN MODEL去進行分類\n",
    "# img = plt.imread('./blues.00000.wav.png')\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path = './genres/'\n",
    "# df = pd.read_csv(path + 'input.mf', delimiter ='\\t', header=None, names=['fullpath', 'style'])\n",
    "# df['filename'] = df[:]['fullpath'].apply(lambda x: path+'/'.join(x.split('/')[-2:]))\n",
    "# df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['filename'][:3].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# for songname in tqdm(df['filename'][:].tolist()):\n",
    "#     cmap = plt.get_cmap('inferno')\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "#     plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "#     plt.axis('off');\n",
    "#     plt.savefig('./CNN/{}.png'.format(songname.split('/')[-1]))\n",
    "#     plt.clf()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './CNN/'\n",
    "# X = []\n",
    "# import os\n",
    "# for root, dirs, files in os.walk(path):\n",
    "#     for f in files:\n",
    "#         X.append(root + f)\n",
    "\n",
    "# X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(X)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = sorted(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample = pd.read_csv('data.csv')\n",
    "# sample[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_raw = sample.iloc[:, -1].values\n",
    "y = le.fit_transform(y_raw)\n",
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from skimage import color\n",
    "# import numpy as np\n",
    "\n",
    "# path = './CNN/'\n",
    "\n",
    "# def read_image(f):\n",
    "#     img = plt.imread(fname=f)\n",
    "#     img_gray = color.rgb2gray(color.rgba2rgb(img))\n",
    "#     return(img_gray)\n",
    "\n",
    "# X = np.array([read_image(x) for x in X[:] ])        \n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./X.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 720, 720)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.load('./X.npy')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/47645115/oserror-cannot-identify-image-file-dataset-ds-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割數據\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils  import np_utils\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense, Activation #神經層\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 720, 720, 12)      120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 360, 360, 12)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1555200)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                99532864  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 99,533,634\n",
      "Trainable params: 99,533,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立簡單的線性執行的模型\n",
    "model = keras.models.Sequential()\n",
    "# Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n",
    "model.add(Conv2D(filters=12, kernel_size=(3, 3),\n",
    "                 activation='relu', padding='same',\n",
    "                 input_shape=(720, 720, 1))) # 高 寬 RGB\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # kernel_size=(2, 2)\n",
    "model.add(Flatten())                       # fully-connected layer\n",
    "\n",
    "# model.add(Dense(units=256, kernel_initializer='normal', activation='relu'))             # input + hidder layer\n",
    "# model.add(Dense(units=128, kernel_initializer='normal', activation='relu'))  # hidder layer\n",
    "model.add(Dense(units=64, kernel_initializer='normal', activation='relu'))  # hidder layer\n",
    "model.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))# Add output layer\n",
    "\n",
    "# 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "128/128 - 9s - loss: 2.7081 - accuracy: 0.0766 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "128/128 - 5s - loss: 2.3026 - accuracy: 0.0891 - val_loss: 2.3027 - val_accuracy: 0.0938\n",
      "Epoch 3/50\n",
      "128/128 - 5s - loss: 2.3026 - accuracy: 0.1125 - val_loss: 2.3028 - val_accuracy: 0.0938\n",
      "Epoch 4/50\n",
      "128/128 - 5s - loss: 2.3025 - accuracy: 0.0891 - val_loss: 2.3029 - val_accuracy: 0.0938\n",
      "Epoch 5/50\n",
      "128/128 - 5s - loss: 2.3025 - accuracy: 0.1125 - val_loss: 2.3030 - val_accuracy: 0.0938\n",
      "Epoch 6/50\n",
      "128/128 - 5s - loss: 2.3024 - accuracy: 0.1125 - val_loss: 2.3030 - val_accuracy: 0.0938\n",
      "Epoch 7/50\n",
      "128/128 - 5s - loss: 2.3024 - accuracy: 0.1125 - val_loss: 2.3031 - val_accuracy: 0.0938\n",
      "Epoch 8/50\n",
      "128/128 - 5s - loss: 2.3024 - accuracy: 0.1000 - val_loss: 2.3032 - val_accuracy: 0.0938\n",
      "Epoch 9/50\n",
      "128/128 - 5s - loss: 2.3023 - accuracy: 0.1125 - val_loss: 2.3032 - val_accuracy: 0.0938\n",
      "Epoch 10/50\n",
      "128/128 - 5s - loss: 2.3023 - accuracy: 0.1125 - val_loss: 2.3033 - val_accuracy: 0.0938\n",
      "Epoch 11/50\n",
      "128/128 - 5s - loss: 2.3022 - accuracy: 0.1125 - val_loss: 2.3033 - val_accuracy: 0.0938\n",
      "Epoch 12/50\n",
      "128/128 - 5s - loss: 2.3022 - accuracy: 0.1125 - val_loss: 2.3034 - val_accuracy: 0.0938\n",
      "Epoch 13/50\n",
      "128/128 - 5s - loss: 2.3021 - accuracy: 0.1125 - val_loss: 2.3035 - val_accuracy: 0.0938\n",
      "Epoch 14/50\n",
      "128/128 - 5s - loss: 2.3021 - accuracy: 0.1125 - val_loss: 2.3035 - val_accuracy: 0.0938\n",
      "Epoch 15/50\n",
      "128/128 - 5s - loss: 2.3021 - accuracy: 0.1125 - val_loss: 2.3036 - val_accuracy: 0.0938\n",
      "Epoch 16/50\n",
      "128/128 - 5s - loss: 2.3020 - accuracy: 0.1125 - val_loss: 2.3036 - val_accuracy: 0.0938\n",
      "Epoch 17/50\n",
      "128/128 - 5s - loss: 2.3020 - accuracy: 0.1125 - val_loss: 2.3037 - val_accuracy: 0.0938\n",
      "Epoch 18/50\n",
      "128/128 - 5s - loss: 2.3019 - accuracy: 0.1125 - val_loss: 2.3038 - val_accuracy: 0.0938\n",
      "Epoch 19/50\n",
      "128/128 - 5s - loss: 2.3019 - accuracy: 0.1125 - val_loss: 2.3039 - val_accuracy: 0.0938\n",
      "Epoch 20/50\n",
      "128/128 - 5s - loss: 2.3019 - accuracy: 0.1125 - val_loss: 2.3039 - val_accuracy: 0.0938\n",
      "Epoch 21/50\n",
      "128/128 - 5s - loss: 2.3018 - accuracy: 0.1125 - val_loss: 2.3040 - val_accuracy: 0.0938\n",
      "Epoch 22/50\n",
      "128/128 - 5s - loss: 2.3018 - accuracy: 0.1125 - val_loss: 2.3041 - val_accuracy: 0.0938\n",
      "Epoch 23/50\n",
      "128/128 - 5s - loss: 2.3018 - accuracy: 0.1125 - val_loss: 2.3042 - val_accuracy: 0.0938\n",
      "Epoch 24/50\n",
      "128/128 - 5s - loss: 2.3017 - accuracy: 0.1125 - val_loss: 2.3042 - val_accuracy: 0.0938\n",
      "Epoch 25/50\n",
      "128/128 - 5s - loss: 2.3017 - accuracy: 0.1125 - val_loss: 2.3042 - val_accuracy: 0.0938\n",
      "Epoch 26/50\n",
      "128/128 - 5s - loss: 2.3017 - accuracy: 0.1125 - val_loss: 2.3043 - val_accuracy: 0.0938\n",
      "Epoch 27/50\n",
      "128/128 - 5s - loss: 2.3016 - accuracy: 0.1125 - val_loss: 2.3044 - val_accuracy: 0.0938\n",
      "Epoch 28/50\n",
      "128/128 - 5s - loss: 2.3016 - accuracy: 0.1125 - val_loss: 2.3044 - val_accuracy: 0.0938\n",
      "Epoch 29/50\n",
      "128/128 - 5s - loss: 2.3016 - accuracy: 0.1125 - val_loss: 2.3045 - val_accuracy: 0.0938\n",
      "Epoch 30/50\n",
      "128/128 - 5s - loss: 2.3015 - accuracy: 0.1125 - val_loss: 2.3046 - val_accuracy: 0.0938\n",
      "Epoch 31/50\n",
      "128/128 - 5s - loss: 2.3015 - accuracy: 0.1125 - val_loss: 2.3047 - val_accuracy: 0.0938\n",
      "Epoch 32/50\n",
      "128/128 - 5s - loss: 2.3015 - accuracy: 0.1125 - val_loss: 2.3047 - val_accuracy: 0.0938\n",
      "Epoch 33/50\n",
      "128/128 - 5s - loss: 2.3015 - accuracy: 0.1125 - val_loss: 2.3048 - val_accuracy: 0.0938\n",
      "Epoch 34/50\n",
      "128/128 - 5s - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.3048 - val_accuracy: 0.0938\n",
      "Epoch 35/50\n",
      "128/128 - 5s - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.3049 - val_accuracy: 0.0938\n",
      "Epoch 36/50\n",
      "128/128 - 5s - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.3049 - val_accuracy: 0.0938\n",
      "Epoch 37/50\n",
      "128/128 - 5s - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.3050 - val_accuracy: 0.0938\n",
      "Epoch 38/50\n",
      "128/128 - 5s - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3051 - val_accuracy: 0.0938\n",
      "Epoch 39/50\n",
      "128/128 - 5s - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3051 - val_accuracy: 0.0938\n",
      "Epoch 40/50\n",
      "128/128 - 5s - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3052 - val_accuracy: 0.0938\n",
      "Epoch 41/50\n",
      "128/128 - 5s - loss: 2.3013 - accuracy: 0.1125 - val_loss: 2.3052 - val_accuracy: 0.0938\n",
      "Epoch 42/50\n",
      "128/128 - 5s - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3053 - val_accuracy: 0.0938\n",
      "Epoch 43/50\n",
      "128/128 - 5s - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3054 - val_accuracy: 0.0938\n",
      "Epoch 44/50\n",
      "128/128 - 5s - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3054 - val_accuracy: 0.0938\n",
      "Epoch 45/50\n",
      "128/128 - 5s - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3055 - val_accuracy: 0.0938\n",
      "Epoch 46/50\n",
      "128/128 - 5s - loss: 2.3012 - accuracy: 0.1125 - val_loss: 2.3055 - val_accuracy: 0.0938\n",
      "Epoch 47/50\n",
      "128/128 - 5s - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3056 - val_accuracy: 0.0938\n",
      "Epoch 48/50\n",
      "128/128 - 5s - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3056 - val_accuracy: 0.0938\n",
      "Epoch 49/50\n",
      "128/128 - 5s - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3057 - val_accuracy: 0.0938\n",
      "Epoch 50/50\n",
      "128/128 - 5s - loss: 2.3011 - accuracy: 0.1125 - val_loss: 2.3058 - val_accuracy: 0.0938\n",
      "Completed!!\n"
     ]
    }
   ],
   "source": [
    "# 將 training 的 label 進行 one-hot encoding，例如數字 1 經過 One-hot encoding 轉換後是 01\n",
    "y_TrainOneHot = np_utils.to_categorical(y_train) \n",
    "y_TestOneHot = np_utils.to_categorical(y_test) \n",
    "\n",
    "# 將 training 的 input 資料轉為2維\n",
    "X_train_2D = X_train.reshape(X_train.shape[0], 720, 720, 1).astype('float32')  # 自己試試看float64\n",
    "X_test_2D  = X_test.reshape(X_test.shape[0], 720, 720, 1).astype('float32')  # 自己試試看float64\n",
    "\n",
    "\n",
    "X_train_norm = X_train_2D  # 將訊號 0- 255 轉換成 0-1.0\n",
    "X_test_norm = X_test_2D  # 將訊號 0- 255 轉換成 0-1.0\n",
    "\n",
    "# 進行訓練, 訓練過程會存在 train_history 變數中\n",
    "train_history = model.fit(x=X_train_norm, \n",
    "                          y=y_TrainOneHot, \n",
    "                          validation_split=0.2, \n",
    "                          epochs=50,      # <-------------------------------------調整\n",
    "                          batch_size=5,   # 21765\n",
    "                          verbose=2)       # 0 1 2\n",
    "\n",
    "print('Completed!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,12,720,720] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-21-9d58a521c6ae>:4) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_17576]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-9d58a521c6ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 根據 test 數據顯示訓練成果(分數)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# ############################## <--- exam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_TestOneHot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t[Info] Accuracy of testing data = {:2.1f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,12,720,720] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-21-9d58a521c6ae>:4) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_17576]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "# ############################## <--- exam\n",
    "# 根據 test 數據顯示訓練成果(分數)\n",
    "# ############################## <--- exam\n",
    "scores = model.evaluate(X_test_norm, y_TestOneHot)  \n",
    "print()  \n",
    "print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_history.history['loss'], color='red')\n",
    "plt.plot(train_history.history['val_loss'], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(train_history.history['accuracy'], color='red')\n",
    "plt.plot(train_history.history['val_accuracy'], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
